{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b30f2d5",
   "metadata": {},
   "source": [
    "# AllBiomarkers — Informe visual profesional\n",
    "*Generado: 2025-10-12 12:36*\n",
    "\n",
    "Este notebook crea visualizaciones profesionales (solo **matplotlib**, sin seaborn) para datos de biomarcadores.\n",
    "Es **robusto**: detecta automáticamente columnas numéricas (biomarcadores) y columnas de agrupación comunes\n",
    "(p. ej., `DX`, `Diagnosis`, `VISCODE`, `Group`). Si hay múltiples ficheros, intentará unirlos por las claves comunes.\n",
    "\n",
    "> **Uso rápido**: ajusta la celda de configuración, ejecuta todo y revisa las figuras en cada sección.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65c1d15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DATA_FILES = [\n",
    "    \"./data/adni/demographics/PTDEMOG.csv\",\n",
    "    \"./data/adni/demographics/UPENNBIOMK_ROCHE_ELECSYS_11Oct2025.csv\",\n",
    "    \"./data/adni/demographics/All_Subjects_UCSFFSX7_11Oct2025.csv\",\n",
    "    \"./data/adni/demographics/All_Subjects_UCBERKELEY_AMY_6MM_11Oct2025.csv\",\n",
    "]\n",
    "\n",
    "CANDIDATE_KEYS = [\"RID\", \"PTID\", \"Subject\", \"SubjectID\", \"ID\", \"USUBJID\"]\n",
    "\n",
    "GROUP_COLS = [\"DX\", \"Diagnosis\", \"diagnosis\", \"Group\", \"VISCODE\", \"PHASE\"]\n",
    "\n",
    "DROP_DUPLICATES = True\n",
    "COERCE_NUMERIC = True   # Intentar convertir a numérico ignorando errores\n",
    "WINSORIZE_PCT = 0.0     # 0.0 = sin winsorización; ej., 0.01 para recortar 1% colas\n",
    "\n",
    "MIN_NONNA_RATIO = 0.6\n",
    "\n",
    "TOP_K = 24\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39632692",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, math, itertools, warnings, io\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Tuple\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def read_any(path: str) -> pd.DataFrame:\n",
    "    p = str(path).lower()\n",
    "    if p.endswith(\".csv\"):\n",
    "        return pd.read_csv(path)\n",
    "    if p.endswith(\".tsv\"):\n",
    "        return pd.read_csv(path, sep=\"\\t\")\n",
    "    if p.endswith(\".parquet\"):\n",
    "        return pd.read_parquet(path)\n",
    "    if p.endswith(\".xlsx\") or p.endswith(\".xls\"):\n",
    "        return pd.read_excel(path)\n",
    "    raise ValueError(f\"Formato no soportado: {path}\")\n",
    "\n",
    "def common_keys(dfs: List[pd.DataFrame], candidates: List[str]) -> List[str]:\n",
    "    present = [set(df.columns) for df in dfs]\n",
    "    inter = set.intersection(*present) if present else set()\n",
    "    keys = [k for k in candidates if k in inter]\n",
    "    return keys\n",
    "\n",
    "def safe_merge(dfs: List[pd.DataFrame], keys: List[str]) -> pd.DataFrame:\n",
    "    if not dfs:\n",
    "        return pd.DataFrame()\n",
    "    if not keys:\n",
    "        base = dfs[0].copy()\n",
    "        for i, df in enumerate(dfs[1:], start=2):\n",
    "            base = pd.concat([base.reset_index(drop=True), df.reset_index(drop=True)], axis=1)\n",
    "        return base\n",
    "    base = dfs[0].copy()\n",
    "    for df in dfs[1:]:\n",
    "        base = pd.merge(base, df, on=keys, how=\"outer\", suffixes=(\"\", \"_dup\"))\n",
    "        dup_cols = [c for c in base.columns if c.endswith(\"_dup\")]\n",
    "        for c in dup_cols:\n",
    "            orig = c[:-4]\n",
    "            if orig in base.columns:\n",
    "                base[orig] = base[orig].fillna(base[c])\n",
    "                base.drop(columns=[c], inplace=True)\n",
    "    return base\n",
    "\n",
    "def detect_group_cols(df: pd.DataFrame, candidates: List[str]) -> List[str]:\n",
    "    return [c for c in candidates if c in df.columns]\n",
    "\n",
    "def numeric_biomarkers(df: pd.DataFrame, min_non_na_ratio: float) -> List[str]:\n",
    "    n = len(df)\n",
    "    num_cols = []\n",
    "    for c in df.columns:\n",
    "        if pd.api.types.is_numeric_dtype(df[c]):\n",
    "            non_na = df[c].notna().sum() if n else 0\n",
    "            if n == 0 or (non_na / max(1,n)) >= min_non_na_ratio:\n",
    "                num_cols.append(c)\n",
    "    return num_cols\n",
    "\n",
    "def winsorize_series(s: pd.Series, p: float) -> pd.Series:\n",
    "    if p <= 0 or p >= 0.5 or not pd.api.types.is_numeric_dtype(s):\n",
    "        return s\n",
    "    lo = s.quantile(p)\n",
    "    hi = s.quantile(1-p)\n",
    "    return s.clip(lower=lo, upper=hi)\n",
    "\n",
    "def cols_by_missingness(df: pd.DataFrame, cols: List[str]) -> pd.DataFrame:\n",
    "    total = len(df)\n",
    "    data = []\n",
    "    for c in cols:\n",
    "        miss = df[c].isna().sum()\n",
    "        data.append((c, miss, total - miss, (miss/total if total else np.nan)))\n",
    "    out = pd.DataFrame(data, columns=[\"column\",\"missing\",\"non_missing\",\"missing_ratio\"]).sort_values(\"missing_ratio\", ascending=False)\n",
    "    return out\n",
    "\n",
    "def top_variance_cols(df: pd.DataFrame, cols: List[str], k: int) -> List[str]:\n",
    "    v = pd.Series({c: df[c].var(skipna=True) for c in cols})\n",
    "    v = v.replace([np.inf, -np.inf], np.nan).dropna().sort_values(ascending=False)\n",
    "    return list(v.head(k).index)\n",
    "\n",
    "def ncols_nrows(n_plots: int, max_cols: int = 3) -> Tuple[int,int]:\n",
    "    cols = min(max_cols, n_plots)\n",
    "    rows = math.ceil(n_plots / cols) if n_plots else 1\n",
    "    return rows, cols\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff1d5bb",
   "metadata": {},
   "source": [
    "## Carga y unión de ficheros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ecd64ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leídos 4 ficheros:\n",
      " - ./data/adni/demographics/PTDEMOG.csv\n",
      " - ./data/adni/demographics/UPENNBIOMK_ROCHE_ELECSYS_11Oct2025.csv\n",
      " - ./data/adni/demographics/All_Subjects_UCSFFSX7_11Oct2025.csv\n",
      " - ./data/adni/demographics/All_Subjects_UCBERKELEY_AMY_6MM_11Oct2025.csv\n",
      "Claves comunes detectadas: ['RID', 'PTID']\n",
      "Dimensiones del dataset combinado: (136814, 769)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PHASE</th>\n",
       "      <th>PTID</th>\n",
       "      <th>RID</th>\n",
       "      <th>VISCODE</th>\n",
       "      <th>VISCODE2</th>\n",
       "      <th>VISDATE</th>\n",
       "      <th>PTSOURCE</th>\n",
       "      <th>PTGENDER</th>\n",
       "      <th>PTDOB</th>\n",
       "      <th>PTDOBYY</th>\n",
       "      <th>...</th>\n",
       "      <th>RIGHT_PALLIDUM_SUVR</th>\n",
       "      <th>RIGHT_PALLIDUM_VOLUME</th>\n",
       "      <th>RIGHT_PUTAMEN_SUVR</th>\n",
       "      <th>RIGHT_PUTAMEN_VOLUME</th>\n",
       "      <th>RIGHT_THALAMUS_PROPER_SUVR</th>\n",
       "      <th>RIGHT_THALAMUS_PROPER_VOLUME</th>\n",
       "      <th>RIGHT_VENTRALDC_SUVR</th>\n",
       "      <th>RIGHT_VENTRALDC_VOLUME</th>\n",
       "      <th>RIGHT_VESSEL_SUVR</th>\n",
       "      <th>RIGHT_VESSEL_VOLUME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ADNI1</td>\n",
       "      <td>022_S_0001</td>\n",
       "      <td>1</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>1124323200000000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12/1944</td>\n",
       "      <td>1944.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ADNI1</td>\n",
       "      <td>011_S_0002</td>\n",
       "      <td>2</td>\n",
       "      <td>sc</td>\n",
       "      <td>sc</td>\n",
       "      <td>1124236800000000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>04/1931</td>\n",
       "      <td>1931.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ADNIGO</td>\n",
       "      <td>011_S_0002</td>\n",
       "      <td>2</td>\n",
       "      <td>sc</td>\n",
       "      <td>sc</td>\n",
       "      <td>1285113600000000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>04/1931</td>\n",
       "      <td>1931.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ADNI2</td>\n",
       "      <td>011_S_0002</td>\n",
       "      <td>2</td>\n",
       "      <td>v06</td>\n",
       "      <td>m72</td>\n",
       "      <td>1316390400000000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>04/1931</td>\n",
       "      <td>1931.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ADNI1</td>\n",
       "      <td>011_S_0003</td>\n",
       "      <td>3</td>\n",
       "      <td>sc</td>\n",
       "      <td>sc</td>\n",
       "      <td>1124323200000000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>05/1924</td>\n",
       "      <td>1924.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ADNI1</td>\n",
       "      <td>011_S_0003</td>\n",
       "      <td>3</td>\n",
       "      <td>sc</td>\n",
       "      <td>sc</td>\n",
       "      <td>1124323200000000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>05/1924</td>\n",
       "      <td>1924.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ADNI1</td>\n",
       "      <td>011_S_0003</td>\n",
       "      <td>3</td>\n",
       "      <td>sc</td>\n",
       "      <td>sc</td>\n",
       "      <td>1124323200000000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>05/1924</td>\n",
       "      <td>1924.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ADNI1</td>\n",
       "      <td>011_S_0003</td>\n",
       "      <td>3</td>\n",
       "      <td>sc</td>\n",
       "      <td>sc</td>\n",
       "      <td>1124323200000000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>05/1924</td>\n",
       "      <td>1924.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ADNI1</td>\n",
       "      <td>011_S_0003</td>\n",
       "      <td>3</td>\n",
       "      <td>sc</td>\n",
       "      <td>sc</td>\n",
       "      <td>1124323200000000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>05/1924</td>\n",
       "      <td>1924.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ADNI1</td>\n",
       "      <td>011_S_0003</td>\n",
       "      <td>3</td>\n",
       "      <td>sc</td>\n",
       "      <td>sc</td>\n",
       "      <td>1124323200000000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>05/1924</td>\n",
       "      <td>1924.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 769 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    PHASE        PTID  RID VISCODE VISCODE2              VISDATE  PTSOURCE  \\\n",
       "0   ADNI1  022_S_0001    1       f        f  1124323200000000000       1.0   \n",
       "1   ADNI1  011_S_0002    2      sc       sc  1124236800000000000       1.0   \n",
       "2  ADNIGO  011_S_0002    2      sc       sc  1285113600000000000       1.0   \n",
       "3   ADNI2  011_S_0002    2     v06      m72  1316390400000000000       1.0   \n",
       "4   ADNI1  011_S_0003    3      sc       sc  1124323200000000000       1.0   \n",
       "5   ADNI1  011_S_0003    3      sc       sc  1124323200000000000       1.0   \n",
       "6   ADNI1  011_S_0003    3      sc       sc  1124323200000000000       1.0   \n",
       "7   ADNI1  011_S_0003    3      sc       sc  1124323200000000000       1.0   \n",
       "8   ADNI1  011_S_0003    3      sc       sc  1124323200000000000       1.0   \n",
       "9   ADNI1  011_S_0003    3      sc       sc  1124323200000000000       1.0   \n",
       "\n",
       "   PTGENDER    PTDOB  PTDOBYY  ...  RIGHT_PALLIDUM_SUVR  \\\n",
       "0       2.0  12/1944   1944.0  ...                  NaN   \n",
       "1       1.0  04/1931   1931.0  ...                  NaN   \n",
       "2       1.0  04/1931   1931.0  ...                  NaN   \n",
       "3       1.0  04/1931   1931.0  ...                  NaN   \n",
       "4       1.0  05/1924   1924.0  ...                  NaN   \n",
       "5       1.0  05/1924   1924.0  ...                  NaN   \n",
       "6       1.0  05/1924   1924.0  ...                  NaN   \n",
       "7       1.0  05/1924   1924.0  ...                  NaN   \n",
       "8       1.0  05/1924   1924.0  ...                  NaN   \n",
       "9       1.0  05/1924   1924.0  ...                  NaN   \n",
       "\n",
       "   RIGHT_PALLIDUM_VOLUME  RIGHT_PUTAMEN_SUVR  RIGHT_PUTAMEN_VOLUME  \\\n",
       "0                    NaN                 NaN                   NaN   \n",
       "1                    NaN                 NaN                   NaN   \n",
       "2                    NaN                 NaN                   NaN   \n",
       "3                    NaN                 NaN                   NaN   \n",
       "4                    NaN                 NaN                   NaN   \n",
       "5                    NaN                 NaN                   NaN   \n",
       "6                    NaN                 NaN                   NaN   \n",
       "7                    NaN                 NaN                   NaN   \n",
       "8                    NaN                 NaN                   NaN   \n",
       "9                    NaN                 NaN                   NaN   \n",
       "\n",
       "   RIGHT_THALAMUS_PROPER_SUVR  RIGHT_THALAMUS_PROPER_VOLUME  \\\n",
       "0                         NaN                           NaN   \n",
       "1                         NaN                           NaN   \n",
       "2                         NaN                           NaN   \n",
       "3                         NaN                           NaN   \n",
       "4                         NaN                           NaN   \n",
       "5                         NaN                           NaN   \n",
       "6                         NaN                           NaN   \n",
       "7                         NaN                           NaN   \n",
       "8                         NaN                           NaN   \n",
       "9                         NaN                           NaN   \n",
       "\n",
       "   RIGHT_VENTRALDC_SUVR  RIGHT_VENTRALDC_VOLUME  RIGHT_VESSEL_SUVR  \\\n",
       "0                   NaN                     NaN                NaN   \n",
       "1                   NaN                     NaN                NaN   \n",
       "2                   NaN                     NaN                NaN   \n",
       "3                   NaN                     NaN                NaN   \n",
       "4                   NaN                     NaN                NaN   \n",
       "5                   NaN                     NaN                NaN   \n",
       "6                   NaN                     NaN                NaN   \n",
       "7                   NaN                     NaN                NaN   \n",
       "8                   NaN                     NaN                NaN   \n",
       "9                   NaN                     NaN                NaN   \n",
       "\n",
       "   RIGHT_VESSEL_VOLUME  \n",
       "0                  NaN  \n",
       "1                  NaN  \n",
       "2                  NaN  \n",
       "3                  NaN  \n",
       "4                  NaN  \n",
       "5                  NaN  \n",
       "6                  NaN  \n",
       "7                  NaN  \n",
       "8                  NaN  \n",
       "9                  NaN  \n",
       "\n",
       "[10 rows x 769 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dfs = []\n",
    "existing = []\n",
    "for p in DATA_FILES:\n",
    "    if Path(p).exists():\n",
    "        try:\n",
    "            df = read_any(p)\n",
    "            dfs.append(df)\n",
    "            existing.append(p)\n",
    "        except Exception as e:\n",
    "            print(f\"Error leyendo {p}: {e}\")\n",
    "    else:\n",
    "        print(f\"No existe: {p}\")\n",
    "        \n",
    "print(f\"Leídos {len(dfs)} ficheros:\", *existing, sep=\"\\n - \")\n",
    "\n",
    "if not dfs:\n",
    "    raise SystemExit(\"No se encontraron ficheros. Edita DATA_FILES y vuelve a ejecutar.\")\n",
    "\n",
    "dfs = [df.rename(columns=lambda c: str(c).strip()) for df in dfs]\n",
    "\n",
    "keys = common_keys(dfs, CANDIDATE_KEYS)\n",
    "print(\"Claves comunes detectadas:\", keys if keys else \"(ninguna)\")\n",
    "data = safe_merge(dfs, keys)\n",
    "\n",
    "if DROP_DUPLICATES:\n",
    "    data = data.drop_duplicates()\n",
    "\n",
    "if COERCE_NUMERIC:\n",
    "    for c in data.columns:\n",
    "        if data[c].dtype == object:\n",
    "            if any(k in c.lower() for k in [\"date\", \"exam\", \"visit\", \"acq\", \"scan\"]):\n",
    "                try:\n",
    "                    data[c] = pd.to_datetime(data[c], errors=\"ignore\")\n",
    "                except:\n",
    "                    pass\n",
    "            try:\n",
    "                _tmp = pd.to_numeric(data[c], errors=\"coerce\")\n",
    "                if _tmp.notna().sum() >= 0.2 * len(_tmp):\n",
    "                    data[c] = _tmp\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "if WINSORIZE_PCT > 0:\n",
    "    for c in data.columns:\n",
    "        if pd.api.types.is_numeric_dtype(data[c]):\n",
    "            data[c] = winsorize_series(data[c], WINSORIZE_PCT)\n",
    "\n",
    "print(f\"Dimensiones del dataset combinado: {data.shape}\")\n",
    "display(data.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4538d66",
   "metadata": {},
   "source": [
    "## Missingness y calidad de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90c4d28f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'caas_jupyter_tools'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m bio_cols = numeric_biomarkers(data, MIN_NONNA_RATIO)\n\u001b[32m      3\u001b[39m miss_df = cols_by_missingness(data, bio_cols)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcaas_jupyter_tools\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m display_dataframe_to_user\n\u001b[32m      5\u001b[39m display_dataframe_to_user(\u001b[33m\"\u001b[39m\u001b[33mMissingness por biomarcador\u001b[39m\u001b[33m\"\u001b[39m, miss_df)\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Gráfico de barras de missingness (top 30)\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'caas_jupyter_tools'"
     ]
    }
   ],
   "source": [
    "bio_cols = numeric_biomarkers(data, MIN_NONNA_RATIO)\n",
    "miss_df = cols_by_missingness(data, bio_cols)\n",
    "from caas_jupyter_tools import display_dataframe_to_user\n",
    "display_dataframe_to_user(\"Missingness por biomarcador\", miss_df)\n",
    "\n",
    "top = miss_df.head(30)\n",
    "plt.figure()\n",
    "plt.barh(top[\"column\"], top[\"missing_ratio\"])\n",
    "plt.xlabel(\"Proporción de valores perdidos\")\n",
    "plt.ylabel(\"Biomarcador\")\n",
    "plt.title(\"Missingness (Top 30)\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9644c9da",
   "metadata": {},
   "source": [
    "## Distribuciones univariantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0a5a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "bio_cols = numeric_biomarkers(data, MIN_NONNA_RATIO)\n",
    "bio_cols = bio_cols[:TOP_K]\n",
    "\n",
    "rows, cols = ncols_nrows(len(bio_cols), max_cols=3)\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(5*cols, 3.5*rows))\n",
    "axes = np.array(axes).reshape(rows, cols)\n",
    "\n",
    "idx = 0\n",
    "for r in range(rows):\n",
    "    for c in range(cols):\n",
    "        ax = axes[r, c]\n",
    "        if idx < len(bio_cols):\n",
    "            col = bio_cols[idx]\n",
    "            x = data[col].dropna().values\n",
    "            ax.hist(x, bins=30)\n",
    "            ax.set_title(f\"{col} — Histograma\")\n",
    "            ax.set_xlabel(col)\n",
    "            ax.set_ylabel(\"Frecuencia\")\n",
    "        else:\n",
    "            ax.axis(\"off\")\n",
    "        idx += 1\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725c7ab6",
   "metadata": {},
   "source": [
    "## Boxplots por grupo (DX/Diagnosis/VISCODE si existe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1471cf78",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_cols = detect_group_cols(data, GROUP_COLS)\n",
    "print(\"Columnas de grupo detectadas:\", group_cols)\n",
    "\n",
    "if group_cols:\n",
    "    gcol = group_cols[0]\n",
    "    bio_cols = numeric_biomarkers(data, MIN_NONNA_RATIO)[:TOP_K]\n",
    "    n = len(bio_cols)\n",
    "    rows, cols = ncols_nrows(n, max_cols=3)\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(5*cols, 3.8*rows))\n",
    "    axes = np.array(axes).reshape(rows, cols)\n",
    "    idx = 0\n",
    "    for r in range(rows):\n",
    "        for c in range(cols):\n",
    "            ax = axes[r, c]\n",
    "            if idx < n:\n",
    "                col = bio_cols[idx]\n",
    "                groups = []\n",
    "                labels = []\n",
    "                for g, dfg in data[[gcol, col]].dropna().groupby(gcol):\n",
    "                    groups.append(dfg[col].values)\n",
    "                    labels.append(str(g))\n",
    "                ax.boxplot(groups, labels=labels, showfliers=False)\n",
    "                ax.set_title(f\"{col} por {gcol}\")\n",
    "                ax.set_xlabel(gcol)\n",
    "                ax.set_ylabel(col)\n",
    "            else:\n",
    "                ax.axis(\"off\")\n",
    "            idx += 1\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No se detectó una columna de grupo. Omite esta sección o añade una en GROUP_COLS.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18aa6ed",
   "metadata": {},
   "source": [
    "## Correlaciones entre biomarcadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173802b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bio_cols = numeric_biomarkers(data, MIN_NONNA_RATIO)[:TOP_K]\n",
    "corr = data[bio_cols].corr(method=\"pearson\", min_periods=30)\n",
    "\n",
    "plt.figure(figsize=(max(6, 0.28*len(bio_cols)), max(4, 0.28*len(bio_cols))))\n",
    "plt.imshow(corr, aspect=\"auto\")\n",
    "plt.xticks(range(len(bio_cols)), bio_cols, rotation=90)\n",
    "plt.yticks(range(len(bio_cols)), bio_cols)\n",
    "plt.colorbar(label=\"Correlación de Pearson\")\n",
    "plt.title(\"Matriz de correlación de biomarcadores\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbbe191",
   "metadata": {},
   "source": [
    "## Dispersogramas de pares (top varianza)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a4230f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bio_cols = numeric_biomarkers(data, MIN_NONNA_RATIO)\n",
    "top_cols = top_variance_cols(data, bio_cols, k=min(6, len(bio_cols)))\n",
    "\n",
    "pairs = list(itertools.combinations(top_cols, 2))[:9]\n",
    "rows, cols = ncols_nrows(len(pairs), max_cols=3)\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(5*cols, 3.8*rows))\n",
    "axes = np.array(axes).reshape(rows, cols)\n",
    "\n",
    "idx = 0\n",
    "for r in range(rows):\n",
    "    for c in range(cols):\n",
    "        ax = axes[r, c]\n",
    "        if idx < len(pairs):\n",
    "            xcol, ycol = pairs[idx]\n",
    "            dfp = data[[xcol, ycol]].dropna()\n",
    "            ax.scatter(dfp[xcol], dfp[ycol], s=8, alpha=0.7)\n",
    "            ax.set_xlabel(xcol)\n",
    "            ax.set_ylabel(ycol)\n",
    "            ax.set_title(f\"{ycol} vs {xcol}\")\n",
    "        else:\n",
    "            ax.axis(\"off\")\n",
    "        idx += 1\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa8a7d3",
   "metadata": {},
   "source": [
    "## Series temporales por sujeto (si hay fecha/visita e ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af91238b",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_cols = [c for c in data.columns if pd.api.types.is_datetime64_any_dtype(data[c])]\n",
    "visit_cols = [c for c in data.columns if c.upper() in {\"VISCODE\",\"VISIT\",\"VISITCODE\"}]\n",
    "id_cols = [c for c in data.columns if c.upper() in {\"RID\",\"PTID\",\"SUBJECT\",\"SUBJECTID\",\"USUBJID\",\"ID\"}]\n",
    "\n",
    "if (date_cols or visit_cols) and id_cols:\n",
    "    time_col = date_cols[0] if date_cols else visit_cols[0]\n",
    "    sid = id_cols[0]\n",
    "    bio_cols = numeric_biomarkers(data, MIN_NONNA_RATIO)[:6]  # sólo unos pocos para legibilidad\n",
    "    dd = data[[sid, time_col] + bio_cols].dropna(subset=[sid, time_col]).copy()\n",
    "    dd = dd.sort_values([sid, time_col])\n",
    "    counts = dd[sid].value_counts()\n",
    "    multi = counts[counts >= 3].index.tolist()[:4]  # hasta 4 sujetos\n",
    "    plt_count = len(multi) * len(bio_cols)\n",
    "    rows, cols = ncols_nrows(plt_count, max_cols=3)\n",
    "\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(5*cols, 3.8*rows))\n",
    "    axes = np.array(axes).reshape(rows, cols)\n",
    "\n",
    "    idx = 0\n",
    "    for s in multi:\n",
    "        dds = dd[dd[sid] == s]\n",
    "        for col in bio_cols:\n",
    "            ax = axes[idx // cols, idx % cols]\n",
    "            ax.plot(dds[time_col], dds[col], marker=\"o\", linewidth=1)\n",
    "            ax.set_title(f\"{col} — Sujeto {s}\")\n",
    "            ax.set_xlabel(str(time_col))\n",
    "            ax.set_ylabel(col)\n",
    "            idx += 1\n",
    "\n",
    "    while idx < rows*cols:\n",
    "        ax = axes[idx // cols, idx % cols]\n",
    "        ax.axis(\"off\")\n",
    "        idx += 1\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No se detectaron columnas de fecha/visita + ID. Omite series temporales.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9db1337",
   "metadata": {},
   "source": [
    "## Exportación de subconjunto limpio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a70210",
   "metadata": {},
   "outputs": [],
   "source": [
    "bio_cols = numeric_biomarkers(data, MIN_NONNA_RATIO)\n",
    "out_path = Path(\"/mnt/data/biomarkers_clean_export.csv\")\n",
    "data[bio_cols].to_csv(out_path, index=False)\n",
    "print(\"Exportado:\", out_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}